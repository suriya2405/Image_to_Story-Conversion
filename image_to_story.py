# -*- coding: utf-8 -*-
"""Image_to_Story.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13RxNh77WmR4kP0LocEbr71zDie92hMSN
"""

!pip install transformers torch gradio pillow gTTS

from transformers import BlipProcessor, BlipForConditionalGeneration, pipeline
from PIL import Image
import gradio as gr
from gtts import gTTS
import tempfile

processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
generator = pipeline("text-generation", model="gpt2")

def image_to_story(image):
    image = image.convert("RGB")
    inputs = processor(images=image, return_tensors="pt")
    out = model.generate(**inputs)
    caption = processor.decode(out[0], skip_special_tokens=True)
    story = generator(f"Write a short story about: {caption}", max_length=100)[0]['generated_text']

    # Generate speech for the story
    tts = gTTS(text=story)
    tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    tts.save(tmp_file.name)

    return caption, story, tmp_file.name

demo = gr.Interface(
    fn=image_to_story,
    inputs=gr.Image(type="pil"),
    outputs=[
        gr.Text(label="Image Caption"),
        gr.Text(label="Generated Story"),
        gr.Audio(label="Listen to the Story", type="filepath")
    ],
    title="Turn Pictures into Stories with AI",
    description="Upload an image to get a caption, a story, and listen to it"
)

demo.launch()

!apt-get install git

!git clone https://github.com/suriya2405/Image_to_Story-Conversion.git

import os
# Set your GitHub username and email
os.system('git config --global user.email "suriyaa4798@gmail.com"')
os.system('git config --global user.name "suriya2405"')

!git clone https://github.com/suriya2405/Image_to_Story-Conversion.git

!git remote add origin https://github.com/suriya2405/Image_to_Story-Conversion.git

!git branch -M main